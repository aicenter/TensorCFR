#!/usr/bin/env python3
import tensorflow as tf

from src.algorithms.tensorcfr_nn.TensorCFR_Goofstack import TensorCFR_Goofstack
from src.algorithms.tensorcfr_best_response.ExploitabilityByTensorCFR import ExploitabilityByTensorCFR
from src.algorithms.tensorcfr_best_response.TensorCFR_BestResponse import TensorCFR_BestResponse
from src.domains.available_domains import get_domain_by_name
from src.nn.data.postprocessing_ranges import load_nn
from src.utils.other_utils import activate_script
from src.utils.tf_utils import print_tensors
import numpy as np
from src.nn.data.preprocessing_ranges import get_files_in_directory_recursively
import os
import pickle

if __name__ == '__main__' and activate_script():

	domain = get_domain_by_name("IIGS6_gambit_flattened")

	nn_dir = get_files_in_directory_recursively(os.getcwd()+"/src/nn/expl_by_nn_epoch")

	mysteps = 1

	expl_dict = {}

	for nn_epoch in nn_dir:

		tensorcfr = TensorCFR_Goofstack(domain,load_nn(nn_epoch),trunk_depth=0)

		tensorcfr.run_cfr(total_steps=mysteps, delay=5)

		average_strategies_over_steps = tensorcfr.average_strategies_over_steps

		final_expl= []

		for player in [1,2]:

			best_response = TensorCFR_BestResponse(best_responder=player,trunk_strategies=tensorcfr.average_strategies_over_steps['average_strategy_step'+str(mysteps-1)],
		                                       domain=domain,trunk_depth=10)

			final_expl.append(best_response.get_final_best_response_value())

		expl_dict[nn_epoch] = (final_expl[0]+final_expl[1])/2

	with open(os.getcwd()+'expl_per_epoch.pickle', 'wb') as f:
		pickle.dump(expl_dict, f, protocol=pickle.HIGHEST_PROTOCOL)


